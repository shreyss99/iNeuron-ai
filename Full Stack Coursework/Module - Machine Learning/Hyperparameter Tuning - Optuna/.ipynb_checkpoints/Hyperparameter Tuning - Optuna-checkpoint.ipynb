{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a9c64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.9.0-py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (4.59.0)\n",
      "Collecting alembic\n",
      "  Downloading alembic-1.7.4-py3-none-any.whl (209 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (1.4.7)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.5.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: scipy!=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (1.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (20.9)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (1.20.1)\n",
      "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.1.0->optuna) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\programdata\\anaconda3\\lib\\site-packages (from alembic->optuna) (3.10.0)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
      "Collecting autopage>=0.4.0\n",
      "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.2.0-py3-none-any.whl (144 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-2.2.1-py3-none-any.whl (23 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
      "Requirement already satisfied: colorama>=0.3.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.3-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata->alembic->optuna) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from Mako->alembic->optuna) (2.0.1)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=e4e3c2ee8e1e2ab8a579ed074434ab1740718d5634be13eceb82e224cac2b5c6\n",
      "  Stored in directory: c:\\users\\pfsl\\appdata\\local\\pip\\cache\\wheels\\7f\\1a\\65\\84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: pyreadline3, pyperclip, pbr, stevedore, PrettyTable, Mako, importlib-resources, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
      "Successfully installed Mako-1.1.5 PrettyTable-2.2.1 alembic-1.7.4 autopage-0.4.0 cliff-3.9.0 cmaes-0.8.2 cmd2-2.2.0 colorlog-6.5.0 importlib-resources-5.4.0 optuna-2.10.0 pbr-5.6.0 pyperclip-1.8.2 pyreadline3-3.3 stevedore-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcadb0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf4fff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.0-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76c8d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdb60f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "193eb394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Admission_Predict.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4101e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "146eff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GRE Score'] = df['GRE Score'].fillna(df['GRE Score'].mean())\n",
    "df['TOEFL Score'] = df['TOEFL Score'].fillna(df['TOEFL Score'].mean())\n",
    "df['University Rating'] = df['University Rating'].fillna(df['University Rating'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6000f127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.drop(columns=['Serial No.', 'Chance of Admit '], axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bbe8b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>316.807500</td>\n",
       "      <td>107.410000</td>\n",
       "      <td>3.087500</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.452500</td>\n",
       "      <td>8.598925</td>\n",
       "      <td>0.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.473646</td>\n",
       "      <td>6.069514</td>\n",
       "      <td>1.143728</td>\n",
       "      <td>1.006869</td>\n",
       "      <td>0.898478</td>\n",
       "      <td>0.596317</td>\n",
       "      <td>0.498362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.170000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.610000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.062500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GRE Score  TOEFL Score  University Rating         SOP        LOR   \\\n",
       "count  400.000000   400.000000         400.000000  400.000000  400.000000   \n",
       "mean   316.807500   107.410000           3.087500    3.400000    3.452500   \n",
       "std     11.473646     6.069514           1.143728    1.006869    0.898478   \n",
       "min    290.000000    92.000000           1.000000    1.000000    1.000000   \n",
       "25%    308.000000   103.000000           2.000000    2.500000    3.000000   \n",
       "50%    317.000000   107.000000           3.000000    3.500000    3.500000   \n",
       "75%    325.000000   112.000000           4.000000    4.000000    4.000000   \n",
       "max    340.000000   120.000000           5.000000    5.000000    5.000000   \n",
       "\n",
       "             CGPA    Research  \n",
       "count  400.000000  400.000000  \n",
       "mean     8.598925    0.547500  \n",
       "std      0.596317    0.498362  \n",
       "min      6.800000    0.000000  \n",
       "25%      8.170000    0.000000  \n",
       "50%      8.610000    1.000000  \n",
       "75%      9.062500    1.000000  \n",
       "max      9.920000    1.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc6b2d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Chance of Admit \n",
       "0                0.92\n",
       "1                0.76\n",
       "2                0.72\n",
       "3                0.80\n",
       "4                0.65\n",
       "..                ...\n",
       "395              0.82\n",
       "396              0.84\n",
       "397              0.91\n",
       "398              0.67\n",
       "399              0.95\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[['Chance of Admit ']]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad5bb641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_scaled_arr = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7f8f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_method is a parameter in XGBoost library which has values as gpu_hit and it will increase the computation\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def objective(trials, data = x, target = y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.10, random_state=30)\n",
    "    \n",
    "    param = {\n",
    "        #'tree_method' : 'gpu_hist', # commented because there is no GPU\n",
    "        'lambda' : trials.suggest_loguniform('lambda', 1e-4, 10.0),\n",
    "        'alpha' : trials.suggest_loguniform('alpha', 1e-4, 10.0),\n",
    "        'colsample_bytree' : trials.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n",
    "        'subsample' : trials.suggest_categorical('subsample', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n",
    "        'learning_rate' : trials.suggest_categorical('learning_rate', [0.001,0.003,0.005,0.008,0.02,0.01,1,10,20]),\n",
    "        'n_estimator' : trials.suggest_categorical('n_estimator', [1,5,10,20,20,50,100]),\n",
    "        'max_depth' : trials.suggest_categorical('max_depth', [3,4,5,6,7,8,9,10]),\n",
    "        'random_state' : trials.suggest_categorical('random_state', [10,20,30,50,100]),\n",
    "        'min_child_weight' : trials.suggest_int('min_child_weight', 1, 200)\n",
    "    }\n",
    "    \n",
    "    xgb_reg_model = xgb.XGBRFRegressor(**param)\n",
    "    xgb_reg_model.fit(x_train, y_train, eval_set=[(x_test, y_test)])\n",
    "    pred_xgb = xgb_reg_model.predict(x_test)\n",
    "    rmse = mean_squared_error(y_test, pred_xgb)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "295b7d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:26,803]\u001b[0m A new study created in memory with name: no-name-36d8a664-ba81-42a6-9a15-5cdecef760d7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:26,937]\u001b[0m Trial 0 finished with value: 0.003214867990237965 and parameters: {'lambda': 5.384831818412256, 'alpha': 0.22233643404876388, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 1, 'n_estimator': 50, 'max_depth': 7, 'random_state': 50, 'min_child_weight': 32}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.14963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:26,996]\u001b[0m Trial 1 finished with value: 0.022389471214641996 and parameters: {'lambda': 0.0009513827518950735, 'alpha': 0.005259016262925875, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 1, 'n_estimator': 100, 'max_depth': 7, 'random_state': 20, 'min_child_weight': 168}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:27,069]\u001b[0m Trial 2 finished with value: 0.07617828597383812 and parameters: {'lambda': 0.0014531226187723008, 'alpha': 0.04070287499442218, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.008, 'n_estimator': 5, 'max_depth': 3, 'random_state': 50, 'min_child_weight': 148}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:27,151]\u001b[0m Trial 3 finished with value: 0.07592874152946105 and parameters: {'lambda': 0.4165509097807398, 'alpha': 5.794721398886922, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.01, 'n_estimator': 20, 'max_depth': 4, 'random_state': 50, 'min_child_weight': 118}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.97454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:27,250]\u001b[0m Trial 4 finished with value: 8.847874824599291 and parameters: {'lambda': 0.2359211092590218, 'alpha': 0.0003569334608400561, 'colsample_bytree': 0.4, 'subsample': 0.3, 'learning_rate': 20, 'n_estimator': 20, 'max_depth': 10, 'random_state': 30, 'min_child_weight': 103}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:4.58613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:27,324]\u001b[0m Trial 5 finished with value: 21.03261675116526 and parameters: {'lambda': 0.1978390979619799, 'alpha': 0.024985674082268823, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 20, 'n_estimator': 50, 'max_depth': 6, 'random_state': 50, 'min_child_weight': 111}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:27,386]\u001b[0m Trial 6 finished with value: 0.07701 and parameters: {'lambda': 0.004280941144746023, 'alpha': 0.1984045302773865, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.001, 'n_estimator': 5, 'max_depth': 9, 'random_state': 50, 'min_child_weight': 199}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:27,465]\u001b[0m Trial 7 finished with value: 0.07648952305295523 and parameters: {'lambda': 1.9036345107213255, 'alpha': 0.00593394192825087, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.005, 'n_estimator': 20, 'max_depth': 3, 'random_state': 100, 'min_child_weight': 123}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:27,541]\u001b[0m Trial 8 finished with value: 0.07493266231840642 and parameters: {'lambda': 0.0032644005709628475, 'alpha': 0.015099657500258651, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.02, 'n_estimator': 5, 'max_depth': 8, 'random_state': 30, 'min_child_weight': 87}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:27,603]\u001b[0m Trial 9 finished with value: 0.07701 and parameters: {'lambda': 0.009543868523570809, 'alpha': 0.09264454925695055, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 10, 'n_estimator': 20, 'max_depth': 7, 'random_state': 20, 'min_child_weight': 180}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.07925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:27,688]\u001b[0m Trial 10 finished with value: 0.006280748361377106 and parameters: {'lambda': 9.619705974525036, 'alpha': 1.6112411122399934, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 1, 'n_estimator': 50, 'max_depth': 5, 'random_state': 10, 'min_child_weight': 19}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.08122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:27,773]\u001b[0m Trial 11 finished with value: 0.006597414761220569 and parameters: {'lambda': 3.9275417528154657, 'alpha': 1.7043641770729914, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 1, 'n_estimator': 50, 'max_depth': 5, 'random_state': 10, 'min_child_weight': 12}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:27,868]\u001b[0m Trial 12 finished with value: 0.07662158938478451 and parameters: {'lambda': 9.999695585663611, 'alpha': 1.0680080560461491, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.003, 'n_estimator': 50, 'max_depth': 5, 'random_state': 10, 'min_child_weight': 10}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.07972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:27,952]\u001b[0m Trial 13 finished with value: 0.006354693219755755 and parameters: {'lambda': 0.03628392638105004, 'alpha': 1.077739123922063, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 1, 'n_estimator': 10, 'max_depth': 5, 'random_state': 10, 'min_child_weight': 54}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:28,053]\u001b[0m Trial 14 finished with value: 0.0033854459895515054 and parameters: {'lambda': 1.3743302768128312, 'alpha': 0.18001457122515538, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 42}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.06495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:28,179]\u001b[0m Trial 15 finished with value: 0.0042190015329138675 and parameters: {'lambda': 0.00010607165410009118, 'alpha': 0.2234449837570402, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 1, 'n_estimator': 1, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 53}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.26313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:28,294]\u001b[0m Trial 16 finished with value: 5.121736211678164 and parameters: {'lambda': 0.6429649756921476, 'alpha': 0.0013187584537251366, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 10, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 48}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:28,377]\u001b[0m Trial 17 finished with value: 0.07598651334709496 and parameters: {'lambda': 1.564009730210783, 'alpha': 0.3031508044724425, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.008, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 76}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:28,471]\u001b[0m Trial 18 finished with value: 0.07647560408894254 and parameters: {'lambda': 0.06179016434876293, 'alpha': 6.366994304683403, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.005, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 40}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:28,553]\u001b[0m Trial 19 finished with value: 0.07558091754629592 and parameters: {'lambda': 0.10427788606921973, 'alpha': 0.07773787736353313, 'colsample_bytree': 0.6, 'subsample': 0.9, 'learning_rate': 0.01, 'n_estimator': 20, 'max_depth': 9, 'random_state': 50, 'min_child_weight': 32}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:28,627]\u001b[0m Trial 20 finished with value: 0.07496842884401614 and parameters: {'lambda': 1.1673821825504689, 'alpha': 0.3845356653936682, 'colsample_bytree': 0.5, 'subsample': 0.3, 'learning_rate': 0.02, 'n_estimator': 20, 'max_depth': 10, 'random_state': 30, 'min_child_weight': 68}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.07265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:28,703]\u001b[0m Trial 21 finished with value: 0.005277662441411833 and parameters: {'lambda': 0.00026995567892792554, 'alpha': 0.13373594606543454, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 1, 'n_estimator': 1, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 62}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:28,788]\u001b[0m Trial 22 finished with value: 0.0034764560457933684 and parameters: {'lambda': 0.014677778877648397, 'alpha': 0.5157398661196531, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 1, 'n_estimator': 1, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 30}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:28,870]\u001b[0m Trial 23 finished with value: 0.0034859983481229607 and parameters: {'lambda': 0.018800331460999225, 'alpha': 0.525150563824827, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 29}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:28,962]\u001b[0m Trial 24 finished with value: 0.07659274769833288 and parameters: {'lambda': 3.9223796619455658, 'alpha': 0.051282996665151584, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.003, 'n_estimator': 20, 'max_depth': 8, 'random_state': 100, 'min_child_weight': 2}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:29,067]\u001b[0m Trial 25 finished with value: 0.07688017068223964 and parameters: {'lambda': 0.020124732396324337, 'alpha': 0.011198543380801375, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.001, 'n_estimator': 20, 'max_depth': 6, 'random_state': 20, 'min_child_weight': 85}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.10041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:29,183]\u001b[0m Trial 26 finished with value: 0.01008231249890835 and parameters: {'lambda': 3.581656796507906, 'alpha': 3.089055601953895, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 50, 'min_child_weight': 25}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.06302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:29,272]\u001b[0m Trial 27 finished with value: 0.003971295746400254 and parameters: {'lambda': 0.09144497681904079, 'alpha': 0.6602265847091928, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 38}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.14962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:29,335]\u001b[0m Trial 28 finished with value: 0.022386693942551272 and parameters: {'lambda': 0.5081163368447806, 'alpha': 0.10197219381839352, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 135}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.08388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:29,408]\u001b[0m Trial 29 finished with value: 0.007035465565244777 and parameters: {'lambda': 0.007243989555243075, 'alpha': 0.031016250524904275, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 1, 'n_estimator': 100, 'max_depth': 7, 'random_state': 20, 'min_child_weight': 80}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.09933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:29,485]\u001b[0m Trial 30 finished with value: 0.009867340479697184 and parameters: {'lambda': 0.20017984289836116, 'alpha': 3.062828283057769, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 50, 'min_child_weight': 42}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:29,566]\u001b[0m Trial 31 finished with value: 0.003369999510367161 and parameters: {'lambda': 0.017449170337011686, 'alpha': 0.4694277684305856, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 25}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:29,649]\u001b[0m Trial 32 finished with value: 0.07593194467951565 and parameters: {'lambda': 0.001761295774443697, 'alpha': 0.6197778439306797, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'n_estimator': 20, 'max_depth': 3, 'random_state': 100, 'min_child_weight': 4}. Best is trial 0 with value: 0.003214867990237965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:29,738]\u001b[0m Trial 33 finished with value: 0.0028219344955621533 and parameters: {'lambda': 0.011555517228857887, 'alpha': 0.25458646874018814, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 19}. Best is trial 33 with value: 0.0028219344955621533.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:29,823]\u001b[0m Trial 34 finished with value: 0.07559931511291337 and parameters: {'lambda': 0.0005026690964294067, 'alpha': 0.19672623707687958, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.01, 'n_estimator': 10, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 19}. Best is trial 33 with value: 0.0028219344955621533.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:4.69157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:29,931]\u001b[0m Trial 35 finished with value: 22.010844445808402 and parameters: {'lambda': 0.040739118789410556, 'alpha': 0.06658808793611658, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 20, 'n_estimator': 20, 'max_depth': 10, 'random_state': 50, 'min_child_weight': 63}. Best is trial 33 with value: 0.0028219344955621533.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:30,030]\u001b[0m Trial 36 finished with value: 0.0027684964874799315 and parameters: {'lambda': 0.0043930322264770895, 'alpha': 0.14495982941914845, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 6, 'random_state': 30, 'min_child_weight': 16}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:30,236]\u001b[0m Trial 37 finished with value: 0.07686346220189126 and parameters: {'lambda': 0.0021409561581049483, 'alpha': 0.0019155424777923629, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.001, 'n_estimator': 20, 'max_depth': 6, 'random_state': 30, 'min_child_weight': 16}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:30,367]\u001b[0m Trial 38 finished with value: 0.07445105921697778 and parameters: {'lambda': 0.0008610546982489603, 'alpha': 0.023119056935525482, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.02, 'n_estimator': 20, 'max_depth': 6, 'random_state': 30, 'min_child_weight': 155}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:5.15707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:30,559]\u001b[0m Trial 39 finished with value: 26.595405298448508 and parameters: {'lambda': 0.005233858413604918, 'alpha': 0.00011362122725739318, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 20, 'n_estimator': 20, 'max_depth': 6, 'random_state': 30, 'min_child_weight': 4}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:1.05034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:30,621]\u001b[0m Trial 40 finished with value: 1.1032064268433666 and parameters: {'lambda': 0.010149555647584291, 'alpha': 9.86985969691412, 'colsample_bytree': 0.4, 'subsample': 0.3, 'learning_rate': 10, 'n_estimator': 20, 'max_depth': 9, 'random_state': 30, 'min_child_weight': 23}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.07372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:30,704]\u001b[0m Trial 41 finished with value: 0.005435014556805352 and parameters: {'lambda': 0.002954712519930361, 'alpha': 0.1334553963859386, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 8, 'random_state': 50, 'min_child_weight': 45}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.08547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:30,835]\u001b[0m Trial 42 finished with value: 0.007305720112211517 and parameters: {'lambda': 0.005854600129461262, 'alpha': 0.2331187619317528, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 1, 'n_estimator': 100, 'max_depth': 3, 'random_state': 30, 'min_child_weight': 97}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:30,957]\u001b[0m Trial 43 finished with value: 0.07629803202186221 and parameters: {'lambda': 0.33118296933137964, 'alpha': 0.05144859245416083, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.005, 'n_estimator': 20, 'max_depth': 7, 'random_state': 20, 'min_child_weight': 32}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.07584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:31,057]\u001b[0m Trial 44 finished with value: 0.005751101359628569 and parameters: {'lambda': 0.0011663221111271323, 'alpha': 1.0570850379578904, 'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 1, 'n_estimator': 50, 'max_depth': 6, 'random_state': 50, 'min_child_weight': 11}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:31,182]\u001b[0m Trial 45 finished with value: 0.07658700062501955 and parameters: {'lambda': 0.8419564181294146, 'alpha': 0.1475036094014929, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.003, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 54}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:31,293]\u001b[0m Trial 46 finished with value: 0.003212439936146473 and parameters: {'lambda': 2.612680023230923, 'alpha': 0.38303248692182607, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 10, 'min_child_weight': 18}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.07938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:31,386]\u001b[0m Trial 47 finished with value: 0.006301259450411734 and parameters: {'lambda': 7.057990795090702, 'alpha': 1.8230017547139754, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 10, 'min_child_weight': 17}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:31,476]\u001b[0m Trial 48 finished with value: 0.0759016352879969 and parameters: {'lambda': 2.626592123367057, 'alpha': 0.33263264214436644, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.008, 'n_estimator': 20, 'max_depth': 10, 'random_state': 10, 'min_child_weight': 11}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.06608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:31,553]\u001b[0m Trial 49 finished with value: 0.004366866316706843 and parameters: {'lambda': 0.02579388448795255, 'alpha': 0.9409372080468565, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 9, 'random_state': 10, 'min_child_weight': 36}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:31,659]\u001b[0m Trial 50 finished with value: 0.07557828802869615 and parameters: {'lambda': 0.013710594476146086, 'alpha': 0.017614148251854724, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.01, 'n_estimator': 20, 'max_depth': 5, 'random_state': 10, 'min_child_weight': 24}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:31,739]\u001b[0m Trial 51 finished with value: 0.0034246793050677683 and parameters: {'lambda': 6.066496103234787, 'alpha': 0.3136296107346275, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 49}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:31,838]\u001b[0m Trial 52 finished with value: 0.00355539260648334 and parameters: {'lambda': 2.267325052372453, 'alpha': 0.1833911858072801, 'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 10, 'min_child_weight': 23}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:31,971]\u001b[0m Trial 53 finished with value: 0.002911619323930941 and parameters: {'lambda': 0.0037946311858070487, 'alpha': 0.09066861237433788, 'colsample_bytree': 0.7, 'subsample': 0.3, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 2}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:32,168]\u001b[0m Trial 54 finished with value: 0.0029023260579348737 and parameters: {'lambda': 0.003401089365197871, 'alpha': 0.11855962949873088, 'colsample_bytree': 0.6, 'subsample': 0.3, 'learning_rate': 1, 'n_estimator': 5, 'max_depth': 7, 'random_state': 30, 'min_child_weight': 1}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:32,364]\u001b[0m Trial 55 finished with value: 0.07628589118128618 and parameters: {'lambda': 0.003723256295432631, 'alpha': 0.03592810439686439, 'colsample_bytree': 0.6, 'subsample': 0.3, 'learning_rate': 0.005, 'n_estimator': 5, 'max_depth': 7, 'random_state': 30, 'min_child_weight': 3}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.31306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:32,475]\u001b[0m Trial 56 finished with value: 5.350271191790176 and parameters: {'lambda': 0.002717646687485301, 'alpha': 0.09163669593193607, 'colsample_bytree': 0.6, 'subsample': 0.3, 'learning_rate': 10, 'n_estimator': 20, 'max_depth': 8, 'random_state': 30, 'min_child_weight': 10}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:32,559]\u001b[0m Trial 57 finished with value: 0.07701 and parameters: {'lambda': 0.0005730698750377188, 'alpha': 0.007121845486872728, 'colsample_bytree': 0.6, 'subsample': 0.3, 'learning_rate': 0.02, 'n_estimator': 20, 'max_depth': 7, 'random_state': 30, 'min_child_weight': 196}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.07031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:32,651]\u001b[0m Trial 58 finished with value: 0.004943720483814228 and parameters: {'lambda': 0.008559352683377371, 'alpha': 0.0593988970791473, 'colsample_bytree': 0.3, 'subsample': 0.3, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 6, 'random_state': 30, 'min_child_weight': 13}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:32,730]\u001b[0m Trial 59 finished with value: 0.07687094750686893 and parameters: {'lambda': 0.0039930319567191615, 'alpha': 0.10586878563811891, 'colsample_bytree': 0.5, 'subsample': 0.3, 'learning_rate': 0.001, 'n_estimator': 20, 'max_depth': 3, 'random_state': 50, 'min_child_weight': 2}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.07765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:32,802]\u001b[0m Trial 60 finished with value: 0.006030110045591857 and parameters: {'lambda': 0.0014690766512009223, 'alpha': 0.29822608212047436, 'colsample_bytree': 0.8, 'subsample': 0.3, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 10, 'min_child_weight': 34}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:32,888]\u001b[0m Trial 61 finished with value: 0.003111143914389756 and parameters: {'lambda': 0.01161082665701952, 'alpha': 0.39833983486084235, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 18}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.06666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:32,969]\u001b[0m Trial 62 finished with value: 0.004443434889303357 and parameters: {'lambda': 0.0110211374384635, 'alpha': 0.7910573510458102, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 17}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.06705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:33,079]\u001b[0m Trial 63 finished with value: 0.00449529219331735 and parameters: {'lambda': 0.04485641578409585, 'alpha': 0.26237392813240884, 'colsample_bytree': 0.4, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 5, 'max_depth': 7, 'random_state': 20, 'min_child_weight': 9}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:33,189]\u001b[0m Trial 64 finished with value: 0.0031766120709650915 and parameters: {'lambda': 0.007360112555775308, 'alpha': 0.44102685439283074, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 1}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.07192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:33,270]\u001b[0m Trial 65 finished with value: 0.005171854136876151 and parameters: {'lambda': 0.006255932440504252, 'alpha': 1.9357062147273554, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 6}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:33,392]\u001b[0m Trial 66 finished with value: 0.07659446807820329 and parameters: {'lambda': 0.002306570606645783, 'alpha': 0.4385976066213265, 'colsample_bytree': 0.6, 'subsample': 0.9, 'learning_rate': 0.003, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 1}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.07014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:33,492]\u001b[0m Trial 67 finished with value: 0.004920039849220059 and parameters: {'lambda': 0.024580370110034784, 'alpha': 1.403806003324931, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 5, 'random_state': 100, 'min_child_weight': 19}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:4.92355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:33,584]\u001b[0m Trial 68 finished with value: 24.24137064710226 and parameters: {'lambda': 0.10720755269568363, 'alpha': 0.139944739491544, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 20, 'n_estimator': 20, 'max_depth': 7, 'random_state': 100, 'min_child_weight': 26}. Best is trial 36 with value: 0.0027684964874799315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:33,730]\u001b[0m Trial 69 finished with value: 0.0025977192932022104 and parameters: {'lambda': 0.005052356421954594, 'alpha': 0.040747389013104825, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 9}. Best is trial 69 with value: 0.0025977192932022104.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.08590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:33,826]\u001b[0m Trial 70 finished with value: 0.007378715693028051 and parameters: {'lambda': 0.004062939512914812, 'alpha': 0.04528946405189205, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 113}. Best is trial 69 with value: 0.0025977192932022104.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:33,943]\u001b[0m Trial 71 finished with value: 0.002632501158052939 and parameters: {'lambda': 0.008239343982881262, 'alpha': 0.07036824631255394, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 9}. Best is trial 69 with value: 0.0025977192932022104.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:34,074]\u001b[0m Trial 72 finished with value: 0.0026263602552281814 and parameters: {'lambda': 0.006981513369616225, 'alpha': 0.07957288165371207, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 9}. Best is trial 69 with value: 0.0025977192932022104.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:34,207]\u001b[0m Trial 73 finished with value: 0.0025862103244855806 and parameters: {'lambda': 0.012317225802183723, 'alpha': 0.027546844207426112, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 9}. Best is trial 73 with value: 0.0025862103244855806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:34,340]\u001b[0m Trial 74 finished with value: 0.0025791945912127827 and parameters: {'lambda': 0.00504085110710538, 'alpha': 0.02708500970061156, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 10}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:34,431]\u001b[0m Trial 75 finished with value: 0.07583852924110901 and parameters: {'lambda': 0.016136084092732636, 'alpha': 0.012412816159392362, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.008, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 9}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:34,523]\u001b[0m Trial 76 finished with value: 0.07557482610741834 and parameters: {'lambda': 0.005183339553246359, 'alpha': 0.02467075827835024, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.01, 'n_estimator': 5, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 29}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:34,667]\u001b[0m Trial 77 finished with value: 0.002597788668764294 and parameters: {'lambda': 0.0018660962717470312, 'alpha': 0.008771493731631774, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 13}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:34,815]\u001b[0m Trial 78 finished with value: 0.0026014902203615646 and parameters: {'lambda': 0.0008454286557512556, 'alpha': 0.0032289668244163366, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 13}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.42148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:35,025]\u001b[0m Trial 79 finished with value: 5.863559304781152 and parameters: {'lambda': 0.0007551994282926781, 'alpha': 0.0024934755867273856, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 10, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 9}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:35,150]\u001b[0m Trial 80 finished with value: 0.07411143669735573 and parameters: {'lambda': 0.0004041601724612512, 'alpha': 0.008626251330763918, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.02, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 13}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:35,275]\u001b[0m Trial 81 finished with value: 0.0028502603444745126 and parameters: {'lambda': 0.001634477093631802, 'alpha': 0.0009493605353770193, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 28}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:35,366]\u001b[0m Trial 82 finished with value: 0.002670230265573852 and parameters: {'lambda': 0.002074742462709487, 'alpha': 0.019575556408841746, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 10, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 22}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:35,497]\u001b[0m Trial 83 finished with value: 0.0026569635093467514 and parameters: {'lambda': 0.00019226224826417084, 'alpha': 0.00417574104866566, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 22}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:35,598]\u001b[0m Trial 84 finished with value: 0.0029397451848418425 and parameters: {'lambda': 0.00015148550720952406, 'alpha': 0.002829549233433137, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 10, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 38}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:35,690]\u001b[0m Trial 85 finished with value: 0.002694352288680664 and parameters: {'lambda': 0.0003200141949661717, 'alpha': 0.005142091975999007, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 23}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:35,801]\u001b[0m Trial 86 finished with value: 0.07627771419335734 and parameters: {'lambda': 0.0011488681266783782, 'alpha': 0.0036939494502891074, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.005, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 8}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:35,902]\u001b[0m Trial 87 finished with value: 0.07686365555076158 and parameters: {'lambda': 0.001985282674807909, 'alpha': 0.01959862640553961, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.001, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 14}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:36,030]\u001b[0m Trial 88 finished with value: 0.002922956937614379 and parameters: {'lambda': 0.00020768557067614004, 'alpha': 0.030066140282685897, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 33}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.08502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:36,112]\u001b[0m Trial 89 finished with value: 0.007227958278069752 and parameters: {'lambda': 0.0011121197933249773, 'alpha': 0.013474610861209381, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 10, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 126}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:36,225]\u001b[0m Trial 90 finished with value: 0.07657447004328777 and parameters: {'lambda': 0.0006924025292543298, 'alpha': 0.004976757367906123, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.003, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 23}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:36,312]\u001b[0m Trial 91 finished with value: 0.0026581736427817282 and parameters: {'lambda': 0.000324936636916852, 'alpha': 0.009027959743257038, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 22}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:36,429]\u001b[0m Trial 92 finished with value: 0.0025833234588521136 and parameters: {'lambda': 0.00013318721523006928, 'alpha': 0.009395780491777026, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 1, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 7}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:36,548]\u001b[0m Trial 93 finished with value: 0.0025979929238048195 and parameters: {'lambda': 0.00017570712427186403, 'alpha': 0.009207836851656182, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 13}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:36,658]\u001b[0m Trial 94 finished with value: 0.0025950453191286725 and parameters: {'lambda': 0.00012445665521086826, 'alpha': 0.0016347862551815966, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 6}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:4.91156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:36,762]\u001b[0m Trial 95 finished with value: 24.12346475525829 and parameters: {'lambda': 0.00017726511725595198, 'alpha': 0.0012522971515890118, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 20, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 6}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:36,876]\u001b[0m Trial 96 finished with value: 0.0029296029456981347 and parameters: {'lambda': 0.0002561656521872841, 'alpha': 0.03925857456268717, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 100, 'min_child_weight': 14}. Best is trial 74 with value: 0.0025791945912127827.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:36,987]\u001b[0m Trial 97 finished with value: 0.0025581892993408522 and parameters: {'lambda': 0.00012552746220058055, 'alpha': 0.06992223607515607, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 20, 'min_child_weight': 6}. Best is trial 97 with value: 0.0025581892993408522.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.05112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:37,110]\u001b[0m Trial 98 finished with value: 0.00261314036243274 and parameters: {'lambda': 0.00011102470375483974, 'alpha': 0.0006828287757915234, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 1, 'n_estimator': 20, 'max_depth': 4, 'random_state': 20, 'min_child_weight': 5}. Best is trial 97 with value: 0.0025581892993408522.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.27540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-31 16:23:37,218]\u001b[0m Trial 99 finished with value: 0.07584623000174724 and parameters: {'lambda': 0.00012110821349295412, 'alpha': 0.0005472161227504711, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.008, 'n_estimator': 20, 'max_depth': 4, 'random_state': 20, 'min_child_weight': 14}. Best is trial 97 with value: 0.0025581892993408522.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lambda': 0.00012552746220058055,\n",
       " 'alpha': 0.06992223607515607,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'subsample': 0.8,\n",
       " 'learning_rate': 1,\n",
       " 'n_estimator': 20,\n",
       " 'max_depth': 4,\n",
       " 'random_state': 20,\n",
       " 'min_child_weight': 6}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_optuna_params = optuna.create_study(direction='minimize')\n",
    "find_optuna_params.optimize(objective, n_trials = 100)\n",
    "find_optuna_params.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56b0e792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda': 0.00012552746220058055,\n",
       " 'alpha': 0.06992223607515607,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'subsample': 0.8,\n",
       " 'learning_rate': 1,\n",
       " 'n_estimator': 20,\n",
       " 'max_depth': 4,\n",
       " 'random_state': 20,\n",
       " 'min_child_weight': 6}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_optuna_params.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78ddd540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_alpha</th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_lambda</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_weight</th>\n",
       "      <th>params_n_estimator</th>\n",
       "      <th>params_random_state</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>2021-10-31 16:23:26.809049</td>\n",
       "      <td>2021-10-31 16:23:26.936609</td>\n",
       "      <td>0 days 00:00:00.127560</td>\n",
       "      <td>0.222336</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.384832</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.022389</td>\n",
       "      <td>2021-10-31 16:23:26.939625</td>\n",
       "      <td>2021-10-31 16:23:26.996103</td>\n",
       "      <td>0 days 00:00:00.056478</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7</td>\n",
       "      <td>168</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.076178</td>\n",
       "      <td>2021-10-31 16:23:26.997967</td>\n",
       "      <td>2021-10-31 16:23:27.066770</td>\n",
       "      <td>0 days 00:00:00.068803</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.008</td>\n",
       "      <td>3</td>\n",
       "      <td>148</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.075929</td>\n",
       "      <td>2021-10-31 16:23:27.070746</td>\n",
       "      <td>2021-10-31 16:23:27.150477</td>\n",
       "      <td>0 days 00:00:00.079731</td>\n",
       "      <td>5.794721</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.416551</td>\n",
       "      <td>0.010</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8.847875</td>\n",
       "      <td>2021-10-31 16:23:27.153472</td>\n",
       "      <td>2021-10-31 16:23:27.249206</td>\n",
       "      <td>0 days 00:00:00.095734</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.235921</td>\n",
       "      <td>20.000</td>\n",
       "      <td>10</td>\n",
       "      <td>103</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>24.123465</td>\n",
       "      <td>2021-10-31 16:23:36.659802</td>\n",
       "      <td>2021-10-31 16:23:36.761497</td>\n",
       "      <td>0 days 00:00:00.101695</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>20.000</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>2021-10-31 16:23:36.763496</td>\n",
       "      <td>2021-10-31 16:23:36.875768</td>\n",
       "      <td>0 days 00:00:00.112272</td>\n",
       "      <td>0.039259</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>2021-10-31 16:23:36.877793</td>\n",
       "      <td>2021-10-31 16:23:36.986568</td>\n",
       "      <td>0 days 00:00:00.108775</td>\n",
       "      <td>0.069922</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>2021-10-31 16:23:36.988563</td>\n",
       "      <td>2021-10-31 16:23:37.109035</td>\n",
       "      <td>0 days 00:00:00.120472</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.075846</td>\n",
       "      <td>2021-10-31 16:23:37.110969</td>\n",
       "      <td>2021-10-31 16:23:37.218297</td>\n",
       "      <td>0 days 00:00:00.107328</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.008</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number      value             datetime_start          datetime_complete  \\\n",
       "0        0   0.003215 2021-10-31 16:23:26.809049 2021-10-31 16:23:26.936609   \n",
       "1        1   0.022389 2021-10-31 16:23:26.939625 2021-10-31 16:23:26.996103   \n",
       "2        2   0.076178 2021-10-31 16:23:26.997967 2021-10-31 16:23:27.066770   \n",
       "3        3   0.075929 2021-10-31 16:23:27.070746 2021-10-31 16:23:27.150477   \n",
       "4        4   8.847875 2021-10-31 16:23:27.153472 2021-10-31 16:23:27.249206   \n",
       "..     ...        ...                        ...                        ...   \n",
       "95      95  24.123465 2021-10-31 16:23:36.659802 2021-10-31 16:23:36.761497   \n",
       "96      96   0.002930 2021-10-31 16:23:36.763496 2021-10-31 16:23:36.875768   \n",
       "97      97   0.002558 2021-10-31 16:23:36.877793 2021-10-31 16:23:36.986568   \n",
       "98      98   0.002613 2021-10-31 16:23:36.988563 2021-10-31 16:23:37.109035   \n",
       "99      99   0.075846 2021-10-31 16:23:37.110969 2021-10-31 16:23:37.218297   \n",
       "\n",
       "                 duration  params_alpha  params_colsample_bytree  \\\n",
       "0  0 days 00:00:00.127560      0.222336                      0.7   \n",
       "1  0 days 00:00:00.056478      0.005259                      0.4   \n",
       "2  0 days 00:00:00.068803      0.040703                      0.9   \n",
       "3  0 days 00:00:00.079731      5.794721                      0.4   \n",
       "4  0 days 00:00:00.095734      0.000357                      0.4   \n",
       "..                    ...           ...                      ...   \n",
       "95 0 days 00:00:00.101695      0.001252                      0.3   \n",
       "96 0 days 00:00:00.112272      0.039259                      0.5   \n",
       "97 0 days 00:00:00.108775      0.069922                      0.7   \n",
       "98 0 days 00:00:00.120472      0.000683                      0.8   \n",
       "99 0 days 00:00:00.107328      0.000547                      0.8   \n",
       "\n",
       "    params_lambda  params_learning_rate  params_max_depth  \\\n",
       "0        5.384832                 1.000                 7   \n",
       "1        0.000951                 1.000                 7   \n",
       "2        0.001453                 0.008                 3   \n",
       "3        0.416551                 0.010                 4   \n",
       "4        0.235921                20.000                10   \n",
       "..            ...                   ...               ...   \n",
       "95       0.000177                20.000                 4   \n",
       "96       0.000256                 1.000                 4   \n",
       "97       0.000126                 1.000                 4   \n",
       "98       0.000111                 1.000                 4   \n",
       "99       0.000121                 0.008                 4   \n",
       "\n",
       "    params_min_child_weight  params_n_estimator  params_random_state  \\\n",
       "0                        32                  50                   50   \n",
       "1                       168                 100                   20   \n",
       "2                       148                   5                   50   \n",
       "3                       118                  20                   50   \n",
       "4                       103                  20                   30   \n",
       "..                      ...                 ...                  ...   \n",
       "95                        6                  20                  100   \n",
       "96                       14                  20                  100   \n",
       "97                        6                  20                   20   \n",
       "98                        5                  20                   20   \n",
       "99                       14                  20                   20   \n",
       "\n",
       "    params_subsample     state  \n",
       "0                0.6  COMPLETE  \n",
       "1                0.6  COMPLETE  \n",
       "2                0.6  COMPLETE  \n",
       "3                1.0  COMPLETE  \n",
       "4                0.3  COMPLETE  \n",
       "..               ...       ...  \n",
       "95               0.8  COMPLETE  \n",
       "96               0.8  COMPLETE  \n",
       "97               0.8  COMPLETE  \n",
       "98               0.8  COMPLETE  \n",
       "99               0.4  COMPLETE  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_optuna_params.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e058b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (5.3.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly) (1.15.0)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly) (1.15.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.3.1 tenacity-8.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e86f69ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\visualization\\_plotly_imports.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtry_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_imports\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# NOQA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m  \u001b[1;31m# NOQA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplotly_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-695793d88f00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_optimization_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_optuna_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\visualization\\_optimization_history.py\u001b[0m in \u001b[0;36mplot_optimization_history\u001b[1;34m(study, target, target_name)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0m_imports\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[0m_check_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_get_optimization_history_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\_imports.py\u001b[0m in \u001b[0;36mcheck\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deferred\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deferred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "# Optimization achieved\n",
    "\n",
    "import plotly\n",
    "\n",
    "optuna.visualization.plot_optimization_history(find_optuna_params.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad4d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118a7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "073e951e",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e51ca187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda': 0.00012552746220058055,\n",
       " 'alpha': 0.06992223607515607,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'subsample': 0.8,\n",
       " 'learning_rate': 1,\n",
       " 'n_estimator': 20,\n",
       " 'max_depth': 4,\n",
       " 'random_state': 20,\n",
       " 'min_child_weight': 6}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_optuna_params.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aaa9ea30",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-56-cc995b1ca607>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-56-cc995b1ca607>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    xgb_new  = xgb.XGBRFRegressor(lambda = 0.00012552746220058055,\u001b[0m\n\u001b[1;37m                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "xgb_new  = xgb.XGBRFRegressor(lambda = 0.00012552746220058055,\n",
    " alpha=0.06992223607515607,\n",
    " colsample_bytree= 0.7,\n",
    " subsample= 0.8,\n",
    " learning_rate= 1,\n",
    " n_estimator= 20,\n",
    " max_depth= 4,\n",
    " random_state= 20,\n",
    " min_child_weight= 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac7ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
